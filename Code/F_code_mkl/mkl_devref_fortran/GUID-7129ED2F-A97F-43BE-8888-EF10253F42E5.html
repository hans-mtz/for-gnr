<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0016)http://localhost -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="DC.Type" content="topic"/>
<meta name="DC.Title" content="Parallelism"/>
<meta name="DC.Relation" scheme="URI" content="GUID-08595766-B4CC-41D8-BB68-AF153377A5BF.html"/>
<meta name="DC.Relation" scheme="URI" content="http://www.intel.com/software/products/softwaredocs_feedback"/>
<meta name="DC.Format" content="XHTML"/>
<meta name="DC.Identifier" content="GUID-7129ED2F-A97F-43BE-8888-EF10253F42E5"/>
<meta name="DC.Language" content="en-US"/>
<link rel="stylesheet" type="text/css" href="intel_css_styles.css"/>
<title>Parallelism</title>

</head>
<body id="GUID-7129ED2F-A97F-43BE-8888-EF10253F42E5">
 <!-- ==============(Start:NavScript)================= -->
 <script src="NavScript.js" language="JavaScript1.2" type="text/javascript"></script>
 <script language="JavaScript1.2" type="text/javascript">WriteNavLink(0);</script>
 <!-- ==============(End:NavScript)================= -->
<p id="header_text" style="margin-bottom : 20pt"><em>Intel&reg; oneAPI Math Kernel Library Developer Reference - Fortran</em></p>


<h1 class="topictitle1">Parallelism</h1>
<div><p>Intel&reg; oneAPI Math Kernel Library offers performance gains through parallelism provided by the symmetric multiprocessing performance (SMP) feature. You can obtain improvements from SMP in the following ways:</p>
<ul class="bullet" id="GUID-248D877C-7973-4B1D-B924-0CB3663B0078"><li><p>One way is based on user-managed threads in the program and further distribution of the operations over the threads based on data decomposition, domain decomposition, control decomposition, or some other parallelizing technique. Each thread can use any of the Intel&reg; oneAPI Math Kernel Library functions (except for the deprecated<span class="option">?lacon</span> LAPACK routine)
  because the library has been designed to be thread-safe. 
  </p>
</li>
<li><p>Another method is to use the FFT and BLAS level 3
      routines. They have been parallelized and require no alterations of your
      application to gain the performance enhancements of multiprocessing.
      Performance using multiple processors on the level 3 BLAS shows excellent
      scaling. Since the threads are called and managed within the library, the
      application does not need to be recompiled thread-safe<span> (see also 
        <a href="GUID-90EE7236-20A4-4B7E-B942-0E00B0AAAE78.html#GUID-90EE7236-20A4-4B7E-B942-0E00B0AAAE78">Fortran 95 Interface
          Conventions</a> in 
        <span>BLAS and Sparse BLAS Routines 
        </span>)</span>. 
    </p>
</li>
<li><p>Yet another method is to use 
      <dfn class="term">tuned LAPACK routines</dfn>. Currently these
      include the single- and double precision flavors of routines for 
      <dfn class="term">QR</dfn> factorization of general matrices,
      triangular factorization of general and symmetric positive-definite matrices,
      solving systems of equations with such matrices, as well as solving symmetric
      eigenvalue problems. 
    </p>
</li>
</ul>
<p>For instructions on setting the number of available
    processors for the BLAS level 3 and LAPACK routines, see 
    <em>Intel&reg; oneAPI Math Kernel Library Developer Guide</em>. 
  </p>
<p id="P_CF_128498338457233">
<div class="tablenoborder"><table cellpadding="4" summary="" id="d433e46" frame="border" border="1" cellspacing="0" rules="all"><thead align="left"><tr><th class="cellrowborder" align="left" valign="top" width="100%" id="d823278e68"><p id="d433e52">Optimization Notice 
              </p>
</th>
</tr>
</thead>
<tbody><tr><td class="bgcolor(#f5f5f5)" bgcolor="#f5f5f5" valign="top" width="100%" headers="d823278e68 "><p>Intel's compilers may or may not optimize to the same degree for non-Intel microprocessors for optimizations that are not unique to Intel microprocessors. These optimizations include SSE2, SSE3, and SSSE3 instruction sets and other optimizations. Intel does not guarantee the availability, functionality, or effectiveness of any optimization on microprocessors not manufactured by Intel. Microprocessor-dependent optimizations in this product are intended for use with Intel microprocessors. Certain optimizations not specific to Intel microarchitecture are reserved for Intel microprocessors. Please refer to the applicable product User and Reference Guides for more information regarding the specific instruction sets covered by this notice. 
              </p>
<p> Notice revision #20110804 
              </p>
</td>
</tr>
</tbody>
</table>
</div>
 This notice covers the following instruction sets: SSE2, SSE4.2, AVX2, AVX-512. 
    </p>
</div>

<div class="familylinks">
<div class="parentlink"><strong>Parent topic:</strong> <a href="GUID-08595766-B4CC-41D8-BB68-AF153377A5BF.html">Overview</a></div>
</div>
<div/>
</body>
</html>
